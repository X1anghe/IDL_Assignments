{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.model_selection import KFold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_in = np.loadtxt('./Datasets/train_in.csv', \n",
    "                  delimiter=',',  \n",
    "                  skiprows=0,      \n",
    "                  dtype=float)       \n",
    "test_in = np.loadtxt('./Datasets/test_in.csv', \n",
    "                  delimiter=',',   \n",
    "                  skiprows=0,      \n",
    "                  dtype=float)       \n",
    "train_out = np.loadtxt('./Datasets/train_out.csv', \n",
    "                  delimiter=',',  \n",
    "                  skiprows=0,      \n",
    "                  dtype=float)       \n",
    "test_out = np.loadtxt('./Datasets/test_out.csv', \n",
    "                  delimiter=',',   \n",
    "                  skiprows=0,      \n",
    "                  dtype=float)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1365, 256) (342, 256) (1365,) (342,)\n",
      "Inputs_train\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(train_in, train_out, train_size=0.8, random_state=0)\n",
    "X_test = test_in\n",
    "y_test = test_out\n",
    "print(X_train.shape, X_val.shape, y_train.shape, y_val.shape)\n",
    "print('Inputs_train', )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input dataset\n",
    "def preprocessing(datasets):\n",
    "    return np.hstack((datasets, np.ones(len(datasets)).reshape(len(datasets),1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dummies(list, array):\n",
    "    for i, each in zip(list, array):\n",
    "        each[int(i)] = 1\n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sigmoid function \n",
    "def sig(x):\n",
    "    return (1/(1+np.exp(-x)))\n",
    "\n",
    "def sig_prime(x):\n",
    "    return (x * (1 - x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "Len_train = len(X_train)\n",
    "Len_val = len(X_val)\n",
    "Len_test = len(X_test)\n",
    "\n",
    "X_train = preprocessing(X_train)\n",
    "X_val = preprocessing(X_val)\n",
    "X_test = preprocessing(X_test)\n",
    "\n",
    "y_train_dummy = np.zeros(Len_train*10).reshape(Len_train, 10)\n",
    "y_train_dummy = get_dummies(y_train, y_train_dummy)\n",
    "y_val_dummy = np.zeros(Len_val*10).reshape(Len_val, 10)\n",
    "y_val_dummy = get_dummies(y_val, y_val_dummy)\n",
    "y_test_dummy = np.zeros(Len_test*10).reshape(Len_test, 10)\n",
    "y_test_dummy = get_dummies(y_test, y_test_dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=5)\n",
    "\n",
    "kfold_index_list = []\n",
    "\n",
    "for cv_index_train, cv_index_test in kf.split(X_train):\n",
    "    kfold_index_list.append((cv_index_train, cv_index_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(lr, w, x, y_dummy):\n",
    "    for iter in range(1000):\n",
    "        for i in range(len(x)):\n",
    "            y_hat = sig(np.dot(x[i], w))\n",
    "\n",
    "\n",
    "            \n",
    "            diff = y_dummy[i] - y_hat\n",
    "            x_re = x[i].reshape(257,1)\n",
    "            # print(y_hat)\n",
    "            sp = sig_prime(y_hat) * diff\n",
    "            w += lr * x_re * sp\n",
    "\n",
    "        if iter % 10 == 0 :\n",
    "            arg_y_hat = np.argmax(sig(np.dot(x, w)), axis=1)\n",
    "            arg_y_dummy = np.argmax(y_dummy, axis=1)\n",
    "            arg_diff = abs(arg_y_dummy - arg_y_hat)\n",
    "            acc = (len(y_dummy)-np.sum(arg_diff>0))/len(y_dummy)\n",
    "            print(sum(arg_diff))\n",
    "        if acc > 0.97:\n",
    "            break\n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "w0 = np.random.normal(loc=0.0, scale=1.0, size=(257, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.random.seed(2022)\n",
    "# w0 = np.random.normal(1,-1,loc=0.0, scale=1.0, size=(257, 10))\n",
    "# lr = 0.3\n",
    "# w = training(lr, w0, X_train, y_train_dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(lr, w, train_x, y_train_dummy):\n",
    "    y_hat = sig(np.dot(train_x, w))\n",
    "    return np.argmax(y_hat, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_experiments = np.zeros(257*10*4).reshape(4, 257,10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_w0(sections):\n",
    "    np.random.seed(2022)\n",
    "    W_experiments = np.zeros(257*10*len(sections)).reshape(len(sections), 257,10)\n",
    "    index = 0\n",
    "    for i in sections:\n",
    "        # print(i[0], i[1])\n",
    "        W_experiments[index] = np.random.uniform(i[0], i[1], size=(257,10))\n",
    "        index += 1\n",
    "    return W_experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.random.seed(2022)\n",
    "# w0 = np.random.uniform(-0.3,0.3,size=(257,10))\n",
    "sections = [(0, 1), (-0.5, 0.5), (-0.3, 0.3), (-0.1, 0.1)]\n",
    "lr = 0.3\n",
    "W_experiments = generate_w0(sections)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_acc(w):\n",
    "    pred_val = predict(lr, w, X_val, y_val_dummy)\n",
    "    acc_val = accuracy_score(y_val, pred_val)\n",
    "\n",
    "    pred_test = predict(lr, w, X_test, y_test_dummy)\n",
    "    acc_test = accuracy_score(y_test, pred_test)\n",
    "\n",
    "    return acc_val, acc_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1405\n",
      "782\n",
      "535\n",
      "542\n",
      "548\n",
      "544\n",
      "568\n",
      "549\n",
      "545\n",
      "544\n",
      "528\n",
      "525\n",
      "525\n",
      "529\n",
      "536\n",
      "125\n",
      "116\n",
      "114\n",
      "109\n",
      "105\n",
      "103\n",
      "103\n",
      "100\n",
      "101\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "100\n",
      "105\n",
      "105\n",
      "105\n",
      "105\n",
      "105\n",
      "105\n",
      "105\n",
      "105\n",
      "105\n",
      "101\n",
      "97\n",
      "97\n",
      "97\n",
      "97\n",
      "97\n",
      "97\n",
      "99\n",
      "99\n",
      "99\n",
      "99\n",
      "99\n",
      "99\n",
      "99\n",
      "99\n",
      "99\n",
      "99\n",
      "97\n",
      "97\n",
      "97\n",
      "97\n",
      "97\n",
      "97\n",
      "97\n",
      "97\n",
      "97\n",
      "97\n",
      "97\n",
      "102\n",
      "102\n",
      "102\n",
      "102\n",
      "102\n",
      "102\n",
      "102\n",
      "102\n",
      "102\n",
      "102\n",
      "102\n",
      "102\n",
      "102\n",
      "102\n",
      "102\n",
      "102\n",
      "102\n",
      "102\n",
      "102\n",
      "102\n",
      "102\n",
      "102\n",
      "102\n",
      "102\n",
      "102\n",
      "102\n",
      "102\n",
      "102\n",
      "102\n",
      "102\n",
      "102\n",
      "102\n",
      "102\n",
      "102\n",
      "Training with weights section:  Completely random\n",
      "Accuracy train:  0.9758241758241758 Accuracy validation 0.956140350877193 Accuracy test 0.887\n"
     ]
    }
   ],
   "source": [
    "w_list = []\n",
    "results = []\n",
    "w_list.clear()\n",
    "results.clear()\n",
    "np.random.seed(2022)\n",
    "w0 = np.random.normal(loc=0.0, scale=0.3, size=(257, 10))\n",
    "w = training(lr, w0, X_train, y_train_dummy)\n",
    "\n",
    "pred_train = predict(lr, w, X_train, y_train_dummy)\n",
    "acc_train = accuracy_score(y_train, pred_train)\n",
    "acc_val, acc_test = generate_acc(w)\n",
    "\n",
    "w_list.append(w)\n",
    "\n",
    "print(\"Training with weights section: \", 'Completely random')\n",
    "print(\"Accuracy train: \", acc_train, \"Accuracy validation\", acc_val, \"Accuracy test\", acc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "Training with weights section:  (0, 1)\n",
      "Accuracy train:  0.189010989010989 Accuracy validation 0.21637426900584794 Accuracy test 0.229\n",
      "Training with weights section:  (-0.5, 0.5)\n",
      "Accuracy train:  0.9736263736263736 Accuracy validation 0.956140350877193 Accuracy test 0.887\n",
      "Training with weights section:  (-0.3, 0.3)\n",
      "Accuracy train:  0.9706959706959707 Accuracy validation 0.9590643274853801 Accuracy test 0.888\n",
      "Training with weights section:  (-0.1, 0.1)\n",
      "Accuracy train:  0.9714285714285714 Accuracy validation 0.956140350877193 Accuracy test 0.883\n"
     ]
    }
   ],
   "source": [
    "for w0_index in range(len(sections)):\n",
    "    print(w0_index)\n",
    "    w0 = W_experiments[w0_index]\n",
    "    w = training(lr, w0, X_train, y_train_dummy)\n",
    "    \n",
    "    pred_train = predict(lr, w, X_train, y_train_dummy)\n",
    "    acc_train = accuracy_score(y_train, pred_train)\n",
    "    acc_val, acc_test = generate_acc(w)\n",
    "\n",
    "    w_list.append(w)\n",
    "    results.append((acc_train, acc_val, acc_test))\n",
    "for i in range(len(sections)):\n",
    "    acc, acc_val, acc_test = results[i]\n",
    "    print(\"Training with weights section: \", sections[i])\n",
    "    print(\"Accuracy train: \", acc, \"Accuracy validation\", acc_val, \"Accuracy test\", acc_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with weights section:  0, 0\n",
      "Accuracy train:  0.9714285714285714 Accuracy validation 0.9619883040935673 Accuracy test 0.876\n"
     ]
    }
   ],
   "source": [
    "w0 = np.zeros(257*10).reshape(257, 10)\n",
    "w = training(lr, w0, X_train, y_train_dummy)\n",
    "\n",
    "pred_train = predict(lr, w, X_train, y_train_dummy)\n",
    "acc_train = accuracy_score(y_train, pred_train)\n",
    "acc_val, acc_test = generate_acc(w)\n",
    "\n",
    "w_list.append(w)\n",
    "\n",
    "print(\"Training with weights section: \", '0, 0')\n",
    "print(\"Accuracy train: \", acc_train, \"Accuracy validation\", acc_val, \"Accuracy test\", acc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(w_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_weight():\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy train:  0.9413919413919414 Accuracy validation 0.956140350877193 Accuracy test 0.873\n",
      "Accuracy train:  0.9633699633699634 Accuracy validation 0.956140350877193 Accuracy test 0.881\n",
      "Accuracy train:  0.9743589743589743 Accuracy validation 0.956140350877193 Accuracy test 0.88\n",
      "Accuracy train:  0.9853479853479854 Accuracy validation 0.9590643274853801 Accuracy test 0.877\n",
      "Accuracy train:  0.9853479853479854 Accuracy validation 0.9444444444444444 Accuracy test 0.874\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(2022)\n",
    "w0 = np.random.uniform(-0.3, 0.3, size=(257,10))\n",
    "lr = 0.3\n",
    "w_list.clear()\n",
    "results.clear()\n",
    "for i in range(5):\n",
    "    w = training(lr, w0, X_train[kfold_index_list[i][0]], y_train_dummy[kfold_index_list[i][0]])\n",
    "\n",
    "    pred_train = predict(lr, w, X_train[kfold_index_list[i][1]], y_train_dummy[kfold_index_list[i][1]])\n",
    "    acc_train = accuracy_score(y_train[kfold_index_list[i][1]], pred_train)\n",
    "\n",
    "    pred_val = predict(lr, w, X_val, y_val_dummy)\n",
    "    acc_val = accuracy_score(y_val, pred_val)\n",
    "\n",
    "    pred_test = predict(lr, w, X_test, y_test_dummy)\n",
    "    acc_test = accuracy_score(y_test, pred_test)\n",
    "\n",
    "    w_list.append(w)\n",
    "    results.append((acc_train, acc_val, acc_test))\n",
    "\n",
    "for acc, acc_val, acc_test in results:\n",
    "    print(\"Accuracy train: \", acc, \"Accuracy validation\", acc_val, \"Accuracy test\", acc_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(w_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[215,   0,   3,   2,   2,   3,   2,   0,   3,   0],\n",
       "       [  0, 113,   0,   0,   1,   0,   0,   0,   2,   1],\n",
       "       [  1,   0,  80,   2,   0,   0,   0,   1,   3,   1],\n",
       "       [  1,   0,   2,  68,   0,   9,   1,   1,   4,   0],\n",
       "       [  3,   2,   6,   0,  76,   1,   1,   3,   2,   3],\n",
       "       [  1,   0,   0,   1,   1,  37,   0,   0,   2,   2],\n",
       "       [  1,   3,   2,   0,   2,   1,  86,   0,   0,   0],\n",
       "       [  0,   2,   2,   2,   1,   2,   0,  56,   4,   1],\n",
       "       [  1,   0,   6,   3,   0,   0,   0,   0,  72,   1],\n",
       "       [  1,   1,   0,   1,   3,   2,   0,   3,   0,  79]], dtype=int64)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## confusion Test\n",
    "np.random.seed(2022)\n",
    "w0 = np.random.uniform(-0.3, 0.3, size=(257,10))\n",
    "w = training(lr, w0, X_train, y_train_dummy)\n",
    "confusion_matrix(predict(lr, w, X_test, y_test_dummy), y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# w0 = np.random.random((257,10))\n",
    "# lr = 0.3\n",
    "# w = training(lr, w0, X_train, y_train_dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_in_sort = np.hstack((test_in, test_out.reshape(1000,1)))\n",
    "test_in_sort = test_in_sort[test_in_sort[:,-1].argsort()]\n",
    "test_in_sort[:,-1] = 1\n",
    "test_out_sort = sorted(test_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 0\n",
    "index_test = []\n",
    "for i in range(len(test_out_sort)):\n",
    "    if test_out_sort[i] > s:\n",
    "        index_test.append(i-1)\n",
    "        s += 1\n",
    "index_test.append(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[223, 344, 445, 524, 610, 665, 755, 819, 911, 1000]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier as knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_model = knn()\n",
    "model_knn = knn_model.fit(train_in,train_out)\n",
    "test_pred_knn = model_knn.predict(test_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000,)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred_knn.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "629\n",
      "263\n",
      "230\n",
      "218\n",
      "214\n",
      "203\n",
      "number: 0 Accuracy test single layer perceptron 0.9596412556053812 knn 0.9775784753363229 D_classify\n",
      "number: 1 Accuracy test single layer perceptron 0.9586776859504132 knn 0.9834710743801653 D_classify\n",
      "number: 2 Accuracy test single layer perceptron 0.8316831683168316 knn 0.8415841584158416 D_classify\n",
      "number: 3 Accuracy test single layer perceptron 0.8354430379746836 knn 0.8734177215189873 D_classify\n",
      "number: 4 Accuracy test single layer perceptron 0.872093023255814 knn 0.9186046511627907 D_classify\n",
      "number: 5 Accuracy test single layer perceptron 0.7090909090909091 knn 0.6545454545454545 D_classify\n",
      "number: 6 Accuracy test single layer perceptron 0.9444444444444444 knn 0.9333333333333333 D_classify\n",
      "number: 7 Accuracy test single layer perceptron 0.875 knn 0.875 D_classify\n",
      "number: 8 Accuracy test single layer perceptron 0.75 knn 0.8586956521739131 D_classify\n",
      "number: 9 Accuracy test single layer perceptron 0.8876404494382022 knn 0.9325842696629213 D_classify\n",
      "Accuracy test single layer perceptron 0.883 knn 0.908\n"
     ]
    }
   ],
   "source": [
    "w0 = np.random.uniform(-0.3, 0.3, size=(257,10))\n",
    "\n",
    "train_in_p = preprocessing(train_in)\n",
    "train_out_dummy = np.zeros(len(train_out)*10).reshape(len(train_out), 10)\n",
    "train_out_dummy = get_dummies(train_out, train_out_dummy)\n",
    "\n",
    "w = training(lr, w0, train_in_p, train_out_dummy)\n",
    "\n",
    "test_out_sort_dummy = np.zeros(Len_test*10).reshape(Len_test, 10)\n",
    "test_out_sort_dummy = get_dummies(test_out_sort, test_out_sort_dummy)\n",
    "\n",
    "start = 0\n",
    "\n",
    "index = 0\n",
    "for end in index_test:\n",
    "    each_test_in = test_in_sort[:][start:end]\n",
    "    each_test_out = test_out_sort[:][start:end]\n",
    "    each_test_out_sort_dummy = test_out_sort_dummy[:][start:end]\n",
    "\n",
    "    pred_test = predict(lr, w, each_test_in, each_test_out_sort_dummy)\n",
    "    pred_test_knn = model_knn.predict(each_test_in[:, 0:-1])\n",
    "    # pred_test_D = D_classify111(dataset=each_test_in[:, 0:-1])\n",
    "\n",
    "    acc_test = accuracy_score(each_test_out, pred_test)\n",
    "    acc_test_knn = accuracy_score(each_test_out, pred_test_knn)\n",
    "    # acc_test_D = accuracy_score(each_test_out, pred_test_D)\n",
    "    print(\"number:\",index,\"Accuracy test\", \"single layer perceptron\",acc_test, \"knn\",acc_test_knn, \"D_classify\")\n",
    "\n",
    "    index += 1\n",
    "    start = end\n",
    "\n",
    "test_out_dummy = np.zeros(Len_test*10).reshape(Len_test, 10)\n",
    "test_out_dummy = get_dummies(test_out, test_out_dummy)\n",
    "test_in_p = preprocessing(test_in)\n",
    "\n",
    "\n",
    "pred_test = predict(lr, w, test_in_p, test_out_dummy)\n",
    "pred_test_knn = model_knn.predict(test_in)\n",
    "# pred_test_D = D_classify111(dataset=test_in)\n",
    "\n",
    "acc_test = accuracy_score(test_out, pred_test)\n",
    "acc_test_knn = accuracy_score(test_out, pred_test_knn)\n",
    "# acc_test_D = accuracy_score(test_out, pred_test_D)\n",
    "print(\"Accuracy test\", \"single layer perceptron\",acc_test, \"knn\",acc_test_knn)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0bd48ae0881e24b9eb52916598f12b5ce0c2fdafddee5692d5ab0d603e0369db"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
