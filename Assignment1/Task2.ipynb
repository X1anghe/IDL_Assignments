{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_in = np.loadtxt('../Datasets/train_in.csv', \n",
    "                  delimiter=',',   # 用于分割各列值的字符\n",
    "                  skiprows=0,      # 跳过前两行\n",
    "                #   usecols=[0, 2],  # 读取并使用第1列和第3列\n",
    "                  dtype=float)       # 使用的数据类型\n",
    "test_in = np.loadtxt('../Datasets/test_in.csv', \n",
    "                  delimiter=',',   # 用于分割各列值的字符\n",
    "                  skiprows=0,      # 跳过前两行\n",
    "                #   usecols=[0, 2],  # 读取并使用第1列和第3列\n",
    "                  dtype=float)       # 使用的数据类型\n",
    "train_out = np.loadtxt('../Datasets/train_out.csv', \n",
    "                  delimiter=',',   # 用于分割各列值的字符\n",
    "                  skiprows=0,      # 跳过前两行\n",
    "                #   usecols=[0, 2],  # 读取并使用第1列和第3列\n",
    "                  dtype=float)       # 使用的数据类型\n",
    "test_out = np.loadtxt('../Datasets/test_out.csv', \n",
    "                  delimiter=',',   # 用于分割各列值的字符\n",
    "                  skiprows=0,      # 跳过前两行\n",
    "                #   usecols=[0, 2],  # 读取并使用第1列和第3列\n",
    "                  dtype=float)       # 使用的数据类型\n",
    "# print(data)\n",
    "# train_in = np.array(train_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1365, 256) (342, 256) (1365,) (342,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train_in, train_out, train_size=0.8, random_state=0)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sigmoid function \n",
    "def sig(x):\n",
    "    return (1/(1+np.exp(-x)))\n",
    "\n",
    "def deridig(y):\n",
    "    return y*(1-y)\n",
    "\n",
    "Len_train = len(X_train)\n",
    "Len_test = len(X_test)\n",
    "\n",
    "# input dataset\n",
    "def preprocessing(datasets):\n",
    "    return np.hstack((datasets, np.ones(len(datasets)).reshape(len(datasets),1)))\n",
    "\n",
    "train_x = preprocessing(X_train)\n",
    "test_x = preprocessing(X_test)\n",
    "test_in_x = preprocessing(test_in)\n",
    "\n",
    "# weight\n",
    "w0 = np.random.random((257,10))\n",
    "\n",
    "# output dataset\n",
    "y = np.zeros(Len_train * 10).reshape(Len_train,10)\n",
    "\n",
    "#\n",
    "np.random.seed(2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1365, 257) (257, 10) (1365, 10) (342, 257)\n"
     ]
    }
   ],
   "source": [
    "print(train_x.shape, w0.shape, y.shape, test_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dummies(list, array):\n",
    "    for i, each in zip(list, array):\n",
    "        each[int(i)] = 1\n",
    "    return array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1365, 257) (257, 10) (1365, 10)\n",
      "[[0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "y_train_dummy = np.zeros(Len_train*10).reshape(Len_train, 10)\n",
    "y_train_dummy = get_dummies(y_train, y_train_dummy)\n",
    "print(train_x.shape, w0.shape, y.shape)\n",
    "print(y_train_dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(lr, w0, train_x, y_train_dummy):\n",
    "    for iter in range(100000):\n",
    "        y = sig(np.dot(train_x, w0))\n",
    "        # e = pow((y_train_dummy - y) * (y_train_dummy - y), 0.5)\n",
    "        e = y_train_dummy - y\n",
    "        if iter % 100 == 0 :\n",
    "           print(sum(sum(abs(e))))\n",
    "        if sum(sum(abs(e))) <= 1e-04:\n",
    "            print(iter)\n",
    "            break\n",
    "        # updata w0(weight)\n",
    "        # print(w0.shape, train_x.shape, e.shape)\n",
    "        # print((1-w0) * w0)\n",
    "        # w0 += lr * np.dot(train_x.T, e) * ((1-w0) * w0)\n",
    "        w0 += lr * np.dot(train_x.T, e)\n",
    "        # print(sum(sum(((1-w0) * w0))))\n",
    "    return w0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1508.9154619730052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/z4/snjl44yd2sz6dxh5_3nlrgyh0000gn/T/ipykernel_19072/2520368122.py:3: RuntimeWarning: overflow encountered in exp\n",
      "  return (1/(1+np.exp(-x)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129.37026030398633\n",
      "118.49980378731483\n",
      "9.60510229192409\n",
      "2.000515190385721\n",
      "0.0006591075373141126\n",
      "0.000451810683677944\n",
      "0.0003514542239921477\n",
      "0.00028960795995736457\n",
      "0.00024706914164889995\n",
      "0.0002158216685767469\n",
      "0.00019181839567856585\n",
      "0.00017276562506490111\n",
      "0.00015725629652265548\n",
      "0.00014437543696753504\n",
      "0.00013350065240970134\n",
      "0.0001241930436397267\n",
      "0.00011613382399215132\n",
      "0.00010908564690687829\n",
      "0.00010286803974116387\n",
      "1951\n"
     ]
    }
   ],
   "source": [
    "# y = np.zeros(Len_train * 10).reshape(Len_train,10)\n",
    "w0 = np.random.random((257,10))\n",
    "lr = 0.3\n",
    "# b0 = 0.4\n",
    "# e = 100\n",
    "w = train(lr, w0, train_x, y_train_dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/z4/snjl44yd2sz6dxh5_3nlrgyh0000gn/T/ipykernel_19072/2520368122.py:3: RuntimeWarning: overflow encountered in exp\n",
      "  return (1/(1+np.exp(-x)))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[248,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0, 203,   0,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0, 159,   0,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0, 109,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,  97,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,  66,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0, 121,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0, 136,   0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0, 118,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0, 108]])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### confusion Train\n",
    "confusion_matrix(np.argmax(sig(np.dot(train_x, w)), axis=1),y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/z4/snjl44yd2sz6dxh5_3nlrgyh0000gn/T/ipykernel_19072/2520368122.py:3: RuntimeWarning: overflow encountered in exp\n",
      "  return (1/(1+np.exp(-x)))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[215,   1,   6,   3,   3,   5,   5,   0,   7,   1],\n",
       "       [  0, 116,   1,   0,   1,   0,   0,   0,   0,   1],\n",
       "       [  4,   2,  88,   3,   5,   0,   7,   7,   3,   1],\n",
       "       [  0,   0,   1,  65,   3,   6,   0,   2,   4,   1],\n",
       "       [  3,   1,   0,   0,  65,   2,   2,   3,   1,   2],\n",
       "       [  0,   0,   0,   2,   2,  40,   4,   0,   7,   0],\n",
       "       [  0,   0,   1,   0,   1,   0,  72,   0,   0,   0],\n",
       "       [  0,   1,   1,   1,   4,   1,   0,  50,   2,   4],\n",
       "       [  1,   0,   3,   4,   0,   0,   0,   0,  68,   2],\n",
       "       [  1,   0,   0,   1,   2,   1,   0,   2,   0,  76]])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### confusion test\n",
    "confusion_matrix(np.argmax(sig(np.dot(test_in_\n",
    "\n",
    "x, w)), axis=1),test_out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preliminaries\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier as knn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sig(x):\n",
    "    return (1/(1+np.exp(-x)))\n",
    "\n",
    "def sig_prime(x):\n",
    "    return (x * (1 - x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_list = []\n",
    "hidden_list = []\n",
    "\n",
    "def xor_net(inputs, weights):\n",
    "    while(mse(w) != 0:)\n",
    "        # predict process\n",
    "        for i in len(input_list):\n",
    "            for w in weights[0][i]:\n",
    "                hidden_list[i] += w * input_list[i]\n",
    "        for i in len(hidden_list):\n",
    "            for w in weights[1][i]:\n",
    "                output += w * hidden_list[i]\n",
    "        p_error = error_prime(hidden_output, y)  # as error function\n",
    "\n",
    "        # update process\n",
    "        for i in len(weights[1]): # update hidden_weights\n",
    "            weights[1][i] += p_error * hidden_list[i]\n",
    "        for i in len(hidden_list): # update hidden\n",
    "            hidden_list[i] = sig_prime(hidden_list[i]) * p_error * weights[1][i]\n",
    "        for i in len(weights[0]): # update input_weights\n",
    "            weights[0][i] += p_error * hidden_list[i]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = np.array(range(0,9,1)).reshape(3,3)\n",
    "hidden_nodes = np.array([0,1,2])\n",
    "d_hidden_nodes = np.array([0,1,2])\n",
    "input_nodes = np.array([0,1,2])\n",
    "y = np.array([4,5,6])\n",
    "temp_weights_in =  np.array([0,1,2]).reshape(3,1)\n",
    "\n",
    "\n",
    "while(mse() != 0):\n",
    "    # predict process\n",
    "    hidden_nodes = sum(input_nodes*temp_weights_in)\n",
    "    output = hidden_nodes.dot(weights[1].T)\n",
    "\n",
    "    error = y - output\n",
    "    p_error = sig_prime(error)\n",
    "\n",
    "    # update process\n",
    "    d_hidden_nodes = sig_prime(hidden_nodes) * p_error * weights[1]\n",
    "    weights[1] += hidden_nodes * p_error\n",
    "    weights[0] += d_hidden_nodes * p_error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_decent(weights, nodes):\n",
    "    d_nodes = sig_prime(nodes[1]) * p_error * weights[1]\n",
    "    weights[1] = lr * nodes[1] * p_error\n",
    "    weights[0] = lr * d_nodes * p_error * nodes[0]\n",
    "    return weights"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
